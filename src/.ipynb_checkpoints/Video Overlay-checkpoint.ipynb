{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "from keras.models import load_model\n",
    "from training.model import get_personlab\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "import numpy as np\n",
    "from time import time\n",
    "from training.config import config\n",
    "import random\n",
    "from training.post_proc import *\n",
    "from training.plot_mine import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time()\n",
    "#model = get_personlab(train=False, with_preprocess_lambda=True,\n",
    "#                      intermediate_supervision=True,\n",
    "#                      intermediate_layer='res4b12_relu',\n",
    "#                      build_base_func=get_resnet101_base,\n",
    "#                      output_stride=16)\n",
    "model = get_personlab(train=False, with_preprocess_lambda=True,\n",
    "                      output_stride=8)\n",
    "print 'Loading time: {}'.format(time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('models/deeprehab_101.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad image appropriately (to match relationship to output_stride as in training)\n",
    "def pad_img(img, mult=16):\n",
    "    h, w, _ = img.shape\n",
    "    \n",
    "    h_pad = 0\n",
    "    w_pad = 0\n",
    "    if (h-1)%mult > 0:\n",
    "        h_pad = mult-((h-1)%mult)\n",
    "    if (w-1)%mult > 0:\n",
    "        w_pad = mult-((w-1)%mult)\n",
    "    return np.pad(img, ((0,h_pad), (0,w_pad), (0,0)), 'constant')\n",
    "\n",
    "#img = cv2.imread('testim.jpg')\n",
    "#img = cv2.resize(img, (0,0), fx=.9, fy=.9)\n",
    "#img = cv2.resize(img, (388,388))\n",
    "#img = pad_img(img)\n",
    "#print 'Image shape: {}'.format(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_kps(preds,img):\n",
    "    #print(preds)\n",
    "    for kp in preds:\n",
    "        k = kp['xy']\n",
    "        ide = kp['id']\n",
    "        #if ide in [8,11,17,18,19,20,21,22]:\n",
    "        cv2.circle(img, (k[0],k[1]), 2, (255,0,0), -1)\n",
    "        \n",
    "def select_kp(preds):\n",
    "    byId = [[] for i in range(23)]\n",
    "    for kp in preds:\n",
    "        byId[kp['id']].append(kp)\n",
    "\n",
    "\n",
    "    selected = []\n",
    "    for i,group in enumerate(byId):\n",
    "        #print(group)\n",
    "        if(len(group) < 1):\n",
    "            continue\n",
    "        maximum = 0\n",
    "        ind = 0\n",
    "        for j,elem in enumerate(group):\n",
    "            if elem['conf'] > maximum:\n",
    "                maximum = elem['conf']\n",
    "                ind = j\n",
    "        selected.append(group[ind])\n",
    "        \n",
    "    return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('vid_1.mp4')\n",
    "#cap.open('vid.mp4')\n",
    "#print(cap.isOpened())\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc('F','M','P','4')\n",
    "#fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "#fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "out = cv2.VideoWriter('output_fp.avi', fourcc, 20.0, (337, 577))#289,225 897,513 385,225 641,369\n",
    "#out = cv2.VideoWriter('output_fp.avi', fourcc, 20.0, (961,545))\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret == False:\n",
    "        break\n",
    "\n",
    "    img = cv2.resize(frame, (0,0), fx=.3, fy=.3)\n",
    "    img = pad_img(img)\n",
    "    shape = img.shape\n",
    "    \n",
    "    #print(shape)\n",
    "    \n",
    "    outputs = model.predict(img[np.newaxis,...])\n",
    "    outputs = [o[0] for o in outputs]\n",
    "\n",
    "    H = compute_heatmaps(kp_maps=outputs[0], short_offsets=outputs[1])\n",
    "    #Gaussian filtering helps when there are multiple local maxima for the same keypoint.\n",
    "    for i in range(17):\n",
    "        H[:,:,i] = gaussian_filter(H[:,:,i], sigma=2)\n",
    "        \n",
    "    pred_kp = get_keypoints(H)\n",
    "    \n",
    "    #print(\"All:\",len(pred_kp))\n",
    "\n",
    "    #selected = select_kp(pred_kp)\n",
    "    \n",
    "    #print(\"Selected:\",len(selected))\n",
    "    \n",
    "    #draw_kps(pred_kp, img)\n",
    "    #draw_kps(selected, img)\n",
    "    \n",
    "    pred_skels = group_skeletons(keypoints=pred_kp, mid_offsets=outputs[2])\n",
    "    #print 'Number of detected skeletons: {}'.format(len(pred_skels))\n",
    "    \n",
    "    plot_poses(img, pred_skels)\n",
    "    \n",
    "    #out.write(img)\n",
    "    \n",
    "    #cv2.imshow('frame',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
